Optimize the data scraper program to easily accommodate large files and solve OOM errors

Our Success StoriesITClient BackgroundClient:A leading tech firm in IndiaIndustry Type:IT ServicesServices:SAAS services, Marketing services, Business consultantOrganization Size:100+Project DescriptionBuilding a large data warehouse that houses projects and tenders data from all over the world that is to be collected from official government websites, multilateral banks, state and local government agencies, data aggregating websites, etc.Our SolutionWe had tried multiple solutions to prevent the program from running out of memory. We used python pandas techniques to control the use of memory which worked for some files and did not work for others. Provided more solutions using vaex ,dask module and datatables.Project DeliverablesDesired changes to the code and committing them to github.Tools usedVscodePythonGithubSlackLanguage/techniques usedChunkingdask Dataframevaexdatatablepython.Skills usedCloudPythonTime complexityWhat are the technical Challenges Faced during Project ExecutionSystem specs requirement was the main issue during this project because the RAM available was too less and got used up quickly.How the Technical Challenges were SolvedTeam viewer to use remote desktop which had higher specs would be sufficient enough to solve the problem.Business ImpactProvided various techniques to solve memory issues.Suggested parallel programming to decrease the execution time by 12% making getting the tender data at a much faster rate.Project SnapshotsProject website urlhttps://github.com/Taiyo-ai/opentenders-euhttps://opentender.eu